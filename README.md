# Тестовое задание для стажировки в VK

Нужно решить задачу бинарной классификации временных рядов.


## Данные
Данные состоят из 3 таблиц:
* `train.parquet` - обучающая выборка
* `test.parquet` - тестовая выборка
* `sample_submission.csv` - пример решения

Обучающая и тестовая выборки состоят из 3 признаков:

* `id` - уникальный идентификатор ряда
* `dates` - массив с временными отметками
* `values` - массив с соответствующими наблюдениями

Целевой признак в обучающей выборке:
* `label` - класс ряда, 0 или 1

Пример решения содержит 2 признака:
* `id` - уникальный идентификатор объекта
* `score` - вероятность класса 1

В качестве целевой метрики используется `ROC-AUC`.


## Результат
Была создана модель типа `XGBoostClassifier` cо следующими параметрами

```python
XGBClassifier(
    colsample_bynode=0.9854611637016292,
    early_stopping_rounds=5,
    eval_metric='auc', 
    learning_rate=0.3339630944107204, 
    max_depth=5, 
    subsample=0.6719843637165629, 
    reg_lambda=83,
    random_state=33
)
```
Благодаря ней удалось получить следующие показатели ROC AUC на двух выборках:
* **0.93** - на обучающей
* **0.89** - на валидационной


## Инструкция

Решение находится в папке `final`, код обучения модели и сборки признаков - в файле `training.ipynb`. 

Папка `final` содержит файл `script.py`. Чтобы запустить этот файл, необходимо скачать этот репозиторий архивом и распаковать его в директорию. 

После чего нужно открыть эту директорию в VS Code или другом редакторе и написать в терминале

```
cd final
python script.py
```
Первая строка позволит перейти в директорию с файлом, а вторая позволит его запустить.

В этот файл передаются не исходная тестовая выборка, а уже ранее обработанная в `training.ipynb`, так как сам процесс обработки занимает много времени. 

В итоге работы соззастся файл `submission.csv`, который и будет содержать предсказания модели. 

Чтобы запустить ноутбук `training.ipynb` необходимо клонировать весь репозиторий к себе на компьютер вместе с данными и тогда вы сможете пройти весь процесс самостоятельно.

